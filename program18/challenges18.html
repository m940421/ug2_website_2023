<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!--  
    Document Title
    =============================================
    -->
    <title>UG2+ Challenge</title>
    <!--  
    Favicons
    =============================================
    -->
    <link rel="apple-touch-icon" sizes="57x57" href="assets/images/favicons/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="assets/images/favicons/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="assets/images/favicons/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="assets/images/favicons/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="assets/images/favicons/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="assets/images/favicons/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="assets/images/favicons/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="assets/images/favicons/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="assets/images/favicons/apple-icon-180x180.png">
    <link rel="icon" type="image/png" sizes="192x192" href="assets/images/favicons/android-icon-192x192.png">
    <link rel="icon" type="image/png" sizes="32x32" href="assets/images/favicons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="96x96" href="assets/images/favicons/favicon-96x96.png">
    <link rel="icon" type="image/png" sizes="16x16" href="assets/images/favicons/favicon-16x16.png">
    <link rel="manifest" href="/manifest.json">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="assets/images/favicons/ms-icon-144x144.png">
    <meta name="theme-color" content="#ffffff">
    <!--  
    Stylesheets
    =============================================
    
    -->
    <!-- Default stylesheets-->
    <link href="assets/lib/bootstrap/dist/css/bootstrap.min.css" rel="stylesheet">
    <!-- Template specific stylesheets-->
    <link href="https://fonts.googleapis.com/css?family=Roboto+Condensed:400,700" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Volkhov:400i" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,600,700,800" rel="stylesheet">
    <link href="assets/lib/animate.css/animate.css" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.1/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
    <link href="assets/lib/et-line-font/et-line-font.css" rel="stylesheet">
    <link href="assets/lib/flexslider/flexslider.css" rel="stylesheet">
    <link href="assets/lib/owl.carousel/dist/assets/owl.carousel.min.css" rel="stylesheet">
    <link href="assets/lib/owl.carousel/dist/assets/owl.theme.default.min.css" rel="stylesheet">
    <link href="assets/lib/magnific-popup/dist/magnific-popup.css" rel="stylesheet">
    <link href="assets/lib/simple-text-rotator/simpletextrotator.css" rel="stylesheet">
    <!-- Main stylesheet and color file-->
    <link href="assets/css/style.css" rel="stylesheet">
    <link id="color-scheme" href="assets/css/colors/default.css" rel="stylesheet">
  </head>
  <body data-spy="scroll" data-target=".onpage-navigation" data-offset="60">
    <a id="ddmenuLink" href="menu.html">Menu</a>
    <main>
      <div class="page-loader">
        <div class="loader">Loading...</div>
      </div>
      
      
      <div class="main">
        <section class="module bg-dark-30 portfolio-page-header" data-background="assets/images/challengesbg.jpg" style="padding: 90px 0;">
          <div class="container">
            <div class="row">
              <div class="col-sm-6 col-sm-offset-3">
                <h2 class="module-title font-alt" style="margin: 0 0 20px">Challenges</h2>
              </div>
            </div>
          </div>
        </section>
        <!-- <div class="alert alert-danger" role="alert" style="margin-bottom: 0px">
          <button class="close" type="button" data-dismiss="alert" aria-hidden="true">&times;</button><center><i class="fa fa-cog fa-spin"></i><strong>Alert!</strong> Don't forget to check the <a style="color: #337ab7; text-decoration: underline" href="submissions.html#changelog">latest changes</a> to the challenge's files and rules. <b>Last update: 04/02/2018</b></center>
        </div> -->
        <section class="module-medium" style="padding-bottom: 0px">
          <div class="container">
            <div class="row">
              <div class="col-sm-6 col-sm-offset-3">
                <h2 class="module-title font-alt">Introduction</h2>
                <div class="module-subtitle font-serif"></div>
              </div>
            </div>
            <div class="row">
              <div class="col-sm-8 col-sm-offset-2">
                <p style="text-align: justify;">UG<sup>2</sup> Prize Challenge evaluates algorithms for enhancement of images/videos at scale. The most successful and innovative teams will be invited to present at the CVPR 2018 workshop. We provide two challenge categories:</p>
                <ol>
                  <li>Image Enhancement to Facilitate Manual Inspection</li>
                  <li>Image Enhancement to Improve Automatic Object Recognition</li>
                </ol>
                <p style="text-align: justify;">Each challenge will have:</p>
                <ul>
                  <li>$25K awarded to the top scoring entry (including travel money to attend CVPR 2018)</li>
                  <li>$12.5K awarded to the runner up (including travel money to attend CVPR 2018)</li>
                </ul>
                <p style="text-align: justify;">Participants may submit algorithms to both of the challenges, with a limit of 3 algorithms submitted per challenge. The <a style="color: #337ab7; text-decoration: underline" href="https://goo.gl/forms/8FV0xi5pYO9D6p7j2">registration form</a> must be completed by one of the team contributors, indicating the team's affiliation, contact information and challenges in which the team will participate.</p>
              </div>
            </div>
            <div class="row" style="padding-top: 30px">
              <div class="col-sm-8 col-sm-offset-2">
                <h3 class="module-title font-serif" style="margin-bottom: 60px">Challenges</h3>

                <h4 class="module-subtitle font-alt" style="margin-bottom: 20px; text-align: left" id="challenge1">1. Image Enhancement to Facilitate Manual Inspection</h4>                
                <p style="text-align: justify;">The first challenge will be an evaluation of the qualitative enhancement of images (super-resolution, de-noising, and deblurring are within scope here) from a sequestered testing dataset. At least one test in the challenge will include calibration chart ground-truth: charts with vertical lines and color calibration data.</p>
                <p style="text-align: justify;">Scoring in this case will make use of human raters voting on perceived improvement. In order to do this, we will use Amazonâ€™s Mechanical Turk service to crowdsource the judgements over large populations of raters. A likert-scale based task will be deployed, whereby a reasonably large number of raters will determine which image, the original or the restored/enhanced version, is of higher quality.</p>
                <p style="text-align: justify;">Further, inspired by visual psychophysics, rater reaction time will be used to gauge the difficulty of presented image pairs. This will allow us to assign weights to each result (i.e., if a rater takes a long time to determine that an enhanced image is better, it may not be as good as a result where the rater immediately made the same conclusion). This will be factored into the final score.</p>

                <h4 class="module-subtitle font-alt" style="margin-bottom: 20px; text-align: left; padding-top: 20px" id="challenge2">2. Image Enhancement to Improve Automatic Object Recognition</h4>                
                <p style="text-align: justify;">The second challenge will be an evaluation of classification improvement. The evaluation protocol will allow participants to make use of some within dataset training data, and as much out of dataset training data as they would like for training / validation purposes. <b>Participants will not be tasked with the creation of novel classification algorithms.</b></p>
                <p style="text-align: justify;"> In order to establish good baselines for classification performance before and after the application of image enhancement and restoration algorithms, the testing will make use of a selection of common deep learning approaches to recognize annotated objects and then considered the correct classification rate. Namely, the Keras versions of the pre-trained networks VGG16 and VGG19, Inception V3, and ResNet50.</p>
                <p>Each candidate restoration or enhancement algorithm will be treated as an image pre-processing step to prepare sequestered test images to be submitted to all four networks, which serve as canonical classification references.</p>

                <h5 class="module-subtitle font-serif" style="margin-bottom: 20px; text-align: left; color: #666">Classification Metrics</h5> 

                <p style="text-align: justify;">The networks used for the UG<sup>2</sup> classification task return a list of the ImageNet synsets along with the probability of the object belonging to each of the synsets classes. However, taking into account that in some cases it is impossible to provide a fine-grained labeling for the annotated objects, we defined 31 super-classes for the dataset most of them composed by more than one ImageNet synset. For example, the Car super-class would contain ImageNet synsets such as <a style="color: #337ab7; text-decoration: underline" href="http://imagenet.stanford.edu/synset?wnid=n02930766">n02930766: cab</a>, <a style="color: #337ab7; text-decoration: underline" href="http://imagenet.stanford.edu/synset?wnid=n03594945">n03594945: jeep</a>, <a style="color: #337ab7; text-decoration: underline" href="http://imagenet.stanford.edu/synset?wnid=n04467665">n04467665: trailer truck</a>, etc.</p>
                <p style="text-align: justify;">That is, each annotated image <i>i</i>  has a single super-class label <i>L<sub>i</sub></i> which in turn is defined by a set of ImageNet synsets <i>L<sub>i</sub>={s<sub>1</sub>, s<sub>2</sub>, ..., s<sub>i</sub>}</i>. For a complete list of the equivalencies between UG<sup>2</sup> superclasses and ImageNet synsets, see: <a style="color: #337ab7; text-decoration: underline" href="https://drive.google.com/open?id=0BzFMgHiPGRshRWRvN0Naem4tWUU"> UG<sup>2</sup>'s' supplemental material</a> </p>
                <p style="text-align: justify; padding-bottom: 50px">To measure accuracy, we observe the number of correctly identified synsets in the top 5 predictions made by each pre-trained network. A prediction is considered to be correct if it's synset belongs to the set of synsets in the ground-truth super-class label. We use two metrics for this. The first measures the rate of detection of at least 1 correctly classified synset class. In other words, for a super-class label (<i>L<sub>i</sub> = {s<sub>1</sub>, ..., s<sub>n</sub></i>}), a network is able to detect 1 or more correctly classified synsets in the top 5 predictions. The second measures the rate of detecting all the possible correct synset classes in the super-class label synset set. For example, for a super-class label (L<sub>i</sub> = {s<sub>1</sub>, s<sub>2</sub>, s<sub>3</sub>}), a network is able to detect 3 correct synsets in the top 5 labels.</p>

              </div>
            </div>
          </div>
        </section>
        
      <a id="ddfooterLink" href="footer_IARPA.html">Footer</a>
      <div class="scroll-up"><a href="#totop"><i class="fa fa-angle-double-up"></i></a></div>
    </main>
    <!--  
    JavaScripts
    =============================================
    -->
    <script src="assets/lib/jquery/dist/jquery.js"></script>
    <script src="assets/lib/bootstrap/dist/js/bootstrap.min.js"></script>
    <script src="assets/lib/wow/dist/wow.js"></script>
    <script src="assets/lib/jquery.mb.ytplayer/dist/jquery.mb.YTPlayer.js"></script>
    <script src="assets/lib/isotope/dist/isotope.pkgd.js"></script>
    <script src="assets/lib/imagesloaded/imagesloaded.pkgd.js"></script>
    <!-- <script src="assets/lib/flexslider/jquery.flexslider.js"></script> -->
    <script src="assets/lib/owl.carousel/dist/owl.carousel.min.js"></script>
    <!-- <script src="assets/lib/smoothscroll.js"></script> -->
    <script src="assets/lib/magnific-popup/dist/jquery.magnific-popup.js"></script>
    <script src="assets/lib/simple-text-rotator/jquery.simple-text-rotator.min.js"></script>
    <script src="assets/js/plugins.js"></script>
    <script src="assets/js/main.js"></script>
    <script src="assets/js/ddmenu.js" type="text/javascript"></script>
    <script src="assets/js/ddfooter.js" type="text/javascript"></script>
</body>
</html>