<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!--  
    Document Title
    =============================================
    -->
    <title>UG2+ Challenge</title>
    <!--  
    Favicons
    =============================================
    -->
    <link rel="apple-touch-icon" sizes="57x57" href="assets/images/favicons/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="assets/images/favicons/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="assets/images/favicons/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="assets/images/favicons/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="assets/images/favicons/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="assets/images/favicons/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="assets/images/favicons/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="assets/images/favicons/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="assets/images/favicons/apple-icon-180x180.png">
    <link rel="icon" type="image/png" sizes="192x192" href="assets/images/favicons/android-icon-192x192.png">
    <link rel="icon" type="image/png" sizes="32x32" href="assets/images/favicons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="96x96" href="assets/images/favicons/favicon-96x96.png">
    <link rel="icon" type="image/png" sizes="16x16" href="assets/images/favicons/favicon-16x16.png">
    <link rel="manifest" href="/manifest.json">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="assets/images/favicons/ms-icon-144x144.png">
    <meta name="theme-color" content="#ffffff">
    <!--  
    Stylesheets
    =============================================
    
    -->
    <!-- Default stylesheets-->
    <link href="assets/lib/bootstrap/dist/css/bootstrap.min.css" rel="stylesheet">
    <!-- Template specific stylesheets-->
    <link href="https://fonts.googleapis.com/css?family=Roboto+Condensed:400,700" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Volkhov:400i" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,600,700,800" rel="stylesheet">
    <link href="assets/lib/animate.css/animate.css" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.1/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
    <link href="assets/lib/et-line-font/et-line-font.css" rel="stylesheet">
    <link href="assets/lib/flexslider/flexslider.css" rel="stylesheet">
    <link href="assets/lib/owl.carousel/dist/assets/owl.carousel.min.css" rel="stylesheet">
    <link href="assets/lib/owl.carousel/dist/assets/owl.theme.default.min.css" rel="stylesheet">
    <link href="assets/lib/magnific-popup/dist/magnific-popup.css" rel="stylesheet">
    <link href="assets/lib/simple-text-rotator/simpletextrotator.css" rel="stylesheet">
    <!-- Main stylesheet and color file-->
    <link href="assets/css/style.css" rel="stylesheet">
    <link id="color-scheme" href="assets/css/colors/default.css" rel="stylesheet">
  </head>
  <body data-spy="scroll" data-target=".onpage-navigation" data-offset="60">
    <a id="ddmenuLink" href="menu.html">Menu</a>
    <main>
      <div class="page-loader">
        <div class="loader">Loading...</div>
      </div>
      
      
      
      <div class="main">

        <section class="module bg-dark-30 portfolio-page-header" data-background="assets/images/faqbg.jpg" style="padding: 90px 0;">
          <div class="container">
            <div class="row">
              <div class="col-sm-6 col-sm-offset-3">
                <h2 class="module-title font-alt" style="margin: 0 0 20px">FAQ</h2>
              </div>
            </div>
          </div>
        </section>
        <!-- <div class="alert alert-danger" role="alert" style=" margin-bottom: 0px">
          <button class="close" type="button" data-dismiss="alert" aria-hidden="true">&times;</button><center><i class="fa fa-cog fa-spin"></i><strong>Alert!</strong> Don't forget to check the <a style="color: #337ab7; text-decoration: underline" href="submissions.html#changelog">latest changes</a> to the challenge's files and rules. <b>Last update: 04/02/2018</b></center>
        </div> -->
        
        <section class="module-medium" style="padding-bottom: 0px">
          <div class="container">            
            <div class="row">
              <div class="col-sm-8 col-sm-offset-2">
                <div role="tabpanel">
                  <ul class="nav nav-tabs font-alt" role="tablist">
                    <li class="active"><a href="#support" data-toggle="tab"><span class="icon-tools-2"></span>About the challenge</a></li>
                    <!-- <li><a href="#sales" data-toggle="tab"><span class="icon-tools-2"></span>sales</a></li> -->
                  </ul>
                  <div class="tab-content">
                    <div class="tab-pane active" id="support">
                      <div class="panel-group" id="accordion">
                        <div class="panel panel-default">
                          <div class="panel-heading">
                            <h4 class="panel-title font-alt"><a data-toggle="collapse" data-parent="#accordion" href="#support1">What will be the input format?</a></h4>
                          </div>
                          <div class="panel-collapse collapse in" id="support1">
                            <div class="panel-body" style="text-align: justify">We will allow for algorithms that receive either JPG or PNG images as their input.
                            </div>
                          </div>
                        </div>
                        <div class="panel panel-default">
                          <div class="panel-heading">
                            <h4 class="panel-title font-alt"><a data-toggle="collapse" data-parent="#accordion" href="#support8">What is the workflow for the Image Enhancement to Improve Automatic Object Recognition Challenge? What will we receive as inputs and how will our outputs be processed?</a></h4>
                          </div>
                          <div class="panel-collapse collapse in" id="support8">
                            <div class="panel-body" style="text-align: justify"> 
                              <img src="assets/images/Challenge2DevKitFlow.png">
                              The input images will be provided to the container at run time through Docker’s mounting option, the images to be provided to the participant's algorithms will be either JPG or PNG frames (participants will have to specify the input format their submissions require). The processed image returned by the algorithms must be in one of the following data types:
                              <ul>
                                <li>JPEG</li>
                                <li>JPG</li>
                                <li>TIFF</li>
                                <li>TIF</li>
                                <li>PNG</li>
                              </ul>

                              <img src="assets/images/Challenge2EvalFlow.png">
                              For the evaluation of the algorithm's improvement on classification (as well as for the Dry Run), we will crop the objects of interest out of the processed images returned by the participants submissions, and proceed to evaluate their classification metrics (see <a style="color: #337ab7; text-decoration: underline" href="https://drive.google.com/drive/folders/1_Mn5e8Qoj3J0vRq02F7UJZ_-XfvLxolc?usp=sharing">Development Kit's Readme</a> on how to run the evaluation code).
                            </div>
                          </div>
                        </div>
                        <div class="panel panel-default">
                          <div class="panel-heading">
                            <h4 class="panel-title font-alt"><a data-toggle="collapse" data-parent="#accordion" href="#support9">Can our enhanced image be of different resolution than the input?</a></h4>
                          </div>
                          <div class="panel-collapse collapse in" id="support9">
                            <div class="panel-body" style="text-align: justify"> 
                              We restrict the output size to be the same as that of the input images. Therefore, participants whose algorithms are focused on enhancing the images resolution (and consequently modify the size of the input image) would then need to resize their output image to that of the input (we will not do any resizing) if they are participating in Challenge 2.

                              In addition to this, it is important to mention that once we crop the extracted object regions out of the processed image we will again resize that extracted crop region to the default input size of the classification networks (224x224 for VGG16, VGG19 and ResNet50 and 299x299 for InceptionV3).
                            </div>
                          </div>
                        </div>
                        <div class="panel panel-default">
                          <div class="panel-heading">
                            <h4 class="panel-title font-alt"><a class="collapsed" data-toggle="collapse" data-parent="#accordion" href="#support2">What will be the input size of the cropped images?  Raw size as extracted from the video?  Or resized / resampled in any manner?</a></h4>
                          </div>
                          <div class="panel-collapse collapse in" id="support2">
                            <div class="panel-body" style="text-align: justify">The cropped images do not have a fixed size, however the cropping extracts a square cropped region (e.g. if the annotation region was 325x214 we would crop a region of 325x325). This is done so that, the images can be resized to be the input size required by each of the classifiers (224x224 for ResNet, VGG16, and VGG19 and 299x299 for Inception) for the evaluation of the automatic object recognition challenge. The submitted algorithms should then be able to work on images of any size/resolution as we would provide as input the whole video frame, process it and then crop the object of interest out of the image.
                            </div>
                          </div>
                        </div>
                        <div class="panel panel-default">
                          <div class="panel-heading">
                            <h4 class="panel-title font-alt"><a data-toggle="collapse" data-parent="#accordion" href="#support3">If the input is a compressed JPEG, are we expected to write an “enhanced” image with further JPEG compression?</a></h4>
                          </div>
                          <div class="panel-collapse collapse in" id="support3">
                            <div class="panel-body" style="text-align: justify">Your algorithm's output can be any image format that is supported by OpenCV. We would process JPEG frames with your algorithm and then crop the objects of interest in each of these frames, saving these cropped images in the same format as that of your algorithm's output.
                            </div>
                          </div>
                        </div>
                        <div class="panel panel-default">
                          <div class="panel-heading">
                            <h4 class="panel-title font-alt"><a data-toggle="collapse" data-parent="#accordion" href="#support4">How will the winner be determined for the Image Enhancement to Improve Automatic Object Recognition Challenge?</a></h4>
                          </div>
                          <div class="panel-collapse collapse in" id="support4">
                            <div class="panel-body" style="text-align: justify">For the evaluation we would do a majority voting considering the highest classification improvement over a majority of the 4 networks (VGG16, VGG19, InceptionV3, ResNet50) on both Rank5-1C and Rank5-AC.  
                            </div>
                          </div>
                        </div>
                        <div class="panel panel-default">
                          <div class="panel-heading">
                            <h4 class="panel-title font-alt"><a data-toggle="collapse" data-parent="#accordion" href="#support5">How should we extract the annotated objects?</a></h4>
                          </div>
                          <div class="panel-collapse collapse in" id="support5">
                            <div class="panel-body" style="text-align: justify">
                              <p>The format of the annotations files is as follows:</p> 
                              <img src="assets/images/annotations.jpg"/>
                              Only the frames in which their objects are not occluded or out of frame (lost) contain valid annotated objects (otherwise the cropped region might not reflect the object specified in the label column). An object is occluded or lost if their value for 7th and 8th column is 1. 
                              We provided a <a href="https://drive.google.com/open?id=1GrbSB8HTD1Wi7pb4_b5v2iKmjRhjFaE5" style="color: #337ab7; text-decoration: underline"> cropping module</a> with the dataset which might help you extract such objects in the same way we did for our paper.
                              It is important to note that for the cropping module, the frames have to be extracted using the method described in the <a href="https://github.com/cvondrick/vatic/#frame-extraction" style="color: #337ab7; text-decoration: underline">vatic annotation tool</a> since the module is tailored to work with the folder structure generated by the tool. However you might adapt it to fit whichever folder structure you have.
                            </div>
                          </div>
                        </div>
                        <div class="panel panel-default">
                          <div class="panel-heading">
                            <h4 class="panel-title font-alt"><a data-toggle="collapse" data-parent="#accordion" href="#support6">Should we consider labels that are excluded from ImageNet, such as "Pedestrians" and "ResolutionChart", in the classification test?</a></h4>
                          </div>
                          <div class="panel-collapse collapse in" id="support6">
                            <div class="panel-body" style=>
                              Both Pedestrians" and "ResolutionChart" are not classes in ImageNet and consequently, they are not included in the pre-trained classification models. Since we do not expect the participants to produce novel algorithms for recognition and instead encourage them to use the pre-trained models, we would not be considering them for evaluation in  Challenge 2 (Image enhancement to improve automatic object recognition).  However, we might consider these classes for Challenge 1 (Image enhancement to facilitate manual inspection) as it has nothing to do with classification. 
                            </div>
                          </div>
                        </div>
                        <div class="panel panel-default">
                          <div class="panel-heading">
                            <h4 class="panel-title font-alt"><a data-toggle="collapse" data-parent="#accordion" href="#support7">There are super-classes that have shared ImageNet labels such as ['Bannister', 'Fence'], why is that?</a></h4>
                          </div>
                          <div class="panel-collapse collapse in" id="support7">
                            <div class="panel-body" style="text-align: justify">
                              Some of the "super-classes" in the UG2ImageNet.txt are a fine grained label of the another super-class.  For instance, the super-class “Fence” is composed by 4 ImageNet synsets (worm fence, picket fence, chainlink fence, and bannister), some of them are also "super-classes” (e.g. ChainlinkFence). 
                              The reason for this is that, for some videos it might be impossible for the annotators to provide a fine-grained annotation label; for example, videos from the Glider and UAV collections contain imagery captured at distances of thousands of feet which might make impossible for the annotators to provide an accurate label among, lets say, different kinds of fences. However, for videos in the Ground collection (which were taken at distances ranging from 30 to 200 feet) we had more control over distance and motion, and were actually able to distinguish some fine-grained ImageNet categories.
                              As for example, we were able to differentiate between any fence, a bannister and a chainlink fence, which are separate classes in ImageNet. So for the Ground dataset, we have bannister, chainlink fence as separate classes and they are not combined in the Fence superclass as in the other two collections.

                            </div>
                          </div>
                        </div>


                      </div>
                    </div>
                    
                  </div>
                </div>
              </div>
            </div>
          </div>
        </section>
            
      <a id="ddfooterLink" href="footer_IARPA.html">Footer</a>
      <div class="scroll-up"><a href="#totop"><i class="fa fa-angle-double-up"></i></a></div>
    </main>
    <!--  
    JavaScripts
    =============================================
    -->
    <script src="assets/lib/jquery/dist/jquery.js"></script>
    <script src="assets/lib/bootstrap/dist/js/bootstrap.min.js"></script>
    <script src="assets/lib/wow/dist/wow.js"></script>
    <script src="assets/lib/jquery.mb.ytplayer/dist/jquery.mb.YTPlayer.js"></script>
    <script src="assets/lib/isotope/dist/isotope.pkgd.js"></script>
    <script src="assets/lib/imagesloaded/imagesloaded.pkgd.js"></script>
    <!-- <script src="assets/lib/flexslider/jquery.flexslider.js"></script> -->
    <script src="assets/lib/owl.carousel/dist/owl.carousel.min.js"></script>
    <!-- <script src="assets/lib/smoothscroll.js"></script> -->
    <script src="assets/lib/magnific-popup/dist/jquery.magnific-popup.js"></script>
    <script src="assets/lib/simple-text-rotator/jquery.simple-text-rotator.min.js"></script>
    <script src="assets/js/plugins.js"></script>
    <script src="assets/js/main.js"></script>
    <script src="assets/js/ddmenu.js" type="text/javascript"></script>
    <script src="assets/js/ddfooter.js" type="text/javascript"></script>
</body>
</html>